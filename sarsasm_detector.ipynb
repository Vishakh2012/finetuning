{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vishakh2012/finetuning/blob/main/sarsasm_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydh9W1LW1RRa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_json(\"/content/drive/MyDrive/Sarcasm_Headlines_Dataset.json\")\n",
        "df = df[['headline','is_sarcastic']]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8XC2dqcCbsa",
        "outputId": "ca769d94-2e59-4001-c942-242b0f92f0d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizerFast\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "id": "YdQEWsPNBoH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHRAdC6u-QZ_",
        "outputId": "483df912-f8a3-4102-ac70-a3d3624ac48f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26709, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubK0_mKg-j6b",
        "outputId": "9e258b0f-736f-4aae-fced-634bbb33fb3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=({'input_ids': TensorSpec(shape=(64, 56), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(64, 56), dtype=tf.int32, name=None)}, TensorSpec(shape=(64,), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "buffer_size = 64\n",
        "\n",
        "is_train = np.random.uniform(size = len(df))<0.8\n",
        "\n",
        "train_raw = (tf.data.Dataset.\n",
        "             from_tensor_slices((dict(tokenizer(list(df['headline'][is_train]), padding = True, truncation = True)),np.array(df['is_sarcastic'])[is_train ])).\n",
        "             shuffle(len(df)).\n",
        "             batch(64,drop_remainder = True)\n",
        "            )\n",
        "\n",
        "train_raw.prefetch(1)\n",
        "\n",
        "test_raw = (tf.data.Dataset.\n",
        "            from_tensor_slices((dict(tokenizer(list(df['headline'][~is_train]), padding = True, truncation = True)),np.array(df['is_sarcastic'])[~is_train ])).\n",
        "            shuffle(len(df)).\n",
        "            batch(64, drop_remainder = True)\n",
        "            )\n",
        "\n",
        "\n",
        "test_raw.prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d6Fbx4JpzcD",
        "outputId": "1393072b-e23e-4907-a433-c590c12d156c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=({'input_ids': TensorSpec(shape=(64, 66), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(64, 66), dtype=tf.int32, name=None)}, TensorSpec(shape=(64,), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ov1V9u6zB-C",
        "outputId": "9af3ba98-8896-491e-e1b0-0a4eb2eb0501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_ids': <tf.Tensor: shape=(64, 66), dtype=int32, numpy=\n",
            "array([[ 101, 3492, 2210, ...,    0,    0,    0],\n",
            "       [ 101, 8554, 3065, ...,    0,    0,    0],\n",
            "       [ 101, 2327, 2702, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [ 101, 5956, 1011, ...,    0,    0,    0],\n",
            "       [ 101, 8958, 2730, ...,    0,    0,    0],\n",
            "       [ 101, 2013, 2369, ...,    0,    0,    0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(64, 66), dtype=int32, numpy=\n",
            "array([[1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}, <tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
            "array([0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
            "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
            "       0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0])>)\n"
          ]
        }
      ],
      "source": [
        "for item in train_raw.take(1):\n",
        "    print(item)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SL_7e1BK3KLQ"
      },
      "outputs": [],
      "source": [
        "# from transformers import create_optimizer\n",
        "# batch_size = 64\n",
        "\n",
        "# num_epochs = 5\n",
        "\n",
        "# batches_per_epoch = len(train_raw) // batch_size\n",
        "\n",
        "# total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "\n",
        "# optimizer, lr_schedule = create_optimizer(\n",
        "#     init_lr=2e-5,\n",
        "#     num_train_steps=total_train_steps,\n",
        "#     weight_decay_rate=0.01,\n",
        "#     num_warmup_steps=500,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dq7xet68M6c",
        "outputId": "0079890c-673d-4155-fadc-da8ece2f61b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "333/333 [==============================] - 162s 408ms/step - loss: 0.2721 - accuracy: 0.8849 - val_loss: 0.2021 - val_accuracy: 0.9179\n",
            "Epoch 2/3\n",
            "333/333 [==============================] - 137s 412ms/step - loss: 0.1087 - accuracy: 0.9610 - val_loss: 0.2522 - val_accuracy: 0.9081\n",
            "Epoch 3/3\n",
            "333/333 [==============================] - 138s 415ms/step - loss: 0.0446 - accuracy: 0.9840 - val_loss: 0.2738 - val_accuracy: 0.9196\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7e1199721300>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from transformers import TFDistilBertForSequenceClassification\n",
        "num_epochs = 3\n",
        "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
        "adam = Adam()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(5e-5),\n",
        "    metrics=[\"accuracy\"],\n",
        "    loss = SparseCategoricalCrossentropy(from_logits = True)\n",
        ")\n",
        "model.fit(\n",
        "    train_raw,\n",
        "    validation_data=test_raw,\n",
        "    epochs = num_epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zafsHx_w9IFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7a5c123-3604-4c39-c85a-028b798d7e6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83/83 [==============================] - 9s 108ms/step - loss: 0.2753 - accuracy: 0.9191\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.27532655000686646, 0.9190512299537659]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "model.evaluate(test_raw)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"man walks on his hand going to work\"\n",
        "text_tok = dict(tokenizer(text , truncation = True, padding = True, return_tensors = 'tf' ))\n",
        "prediction = model.predict(text_tok)\n",
        "\n",
        "logits = prediction.logits\n",
        "\n",
        "probabilities = tf.nn.softmax(logits, axis = 1)\n",
        "print(probabilities)\n",
        "class_probability = probabilities[0]\n",
        "clp = class_probability.numpy()\n",
        "print(class_probability.numpy())\n",
        "\n",
        "if clp[0] > clp[1]:\n",
        "  print(\"this line is not sarcastic\")\n",
        "else:\n",
        "  print(\"this line is sarcastic\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "antPiutMdOij",
        "outputId": "3bf70c13-1857-4eff-bd97-87f912244785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 33ms/step\n",
            "tf.Tensor([[6.7046360e-04 9.9932957e-01]], shape=(1, 2), dtype=float32)\n",
            "[6.7046360e-04 9.9932957e-01]\n",
            "this line is sarcastic\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1ZwvuDxFUSjWBdF-A4aOELUucgRV0pE41",
      "authorship_tag": "ABX9TyMr5w7aqPMg1EHjejXfzshE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}